{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import dspy\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "load_dotenv(\"../.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "turbo = dspy.OpenAI(model=\"gpt-3.5-turbo-instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuestionAnswer(dspy.Signature):\n",
    "    question = dspy.InputField()\n",
    "    answer = dspy.OutputField()\n",
    "\n",
    "\n",
    "class ZeroShot(dspy.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.predictor = dspy.Predict(QuestionAnswer)\n",
    "\n",
    "    def forward(self, question):\n",
    "        return self.predictor(question=question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive\n"
     ]
    }
   ],
   "source": [
    "with dspy.context(lm=turbo):\n",
    "    qa = dspy.Predict(\"statement -> sentiment\")\n",
    "    response = qa(statement=\"Felling good today\")\n",
    "    print(response.sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Large Language Models (LLMs) are advanced AI models that have revolutionized natural language processing (NLP) tasks. They are trained on vast amounts of data and have billions and even trillions of parameters. LLMs have broad applicability across various industries and are poised to reshape the way we interact with technology and access information.\n",
      "Rationale: understand the significance of Large Language Models (LLMs). We will explore their capabilities, training methodologies, and potential impact on various industries.\n"
     ]
    }
   ],
   "source": [
    "with dspy.context(lm=turbo):\n",
    "    document = \"\"\"\n",
    "Large Language Models (LLMs) are advanced AI models that have revolutionized \\\n",
    "natural language processing (NLP) tasks by significantly expanding the data \\\n",
    "used for training and inference. These models, such as GPT-4, are trained on \\\n",
    "vast amounts of data, enabling them to generate text, handle text and image \\\n",
    "inputs (multimodal approach), and perform tasks like translation, text \\\n",
    "summarization, sentiment analysis, and code generation. LLMs are \\\n",
    "characterized by their massive size, with billions and even trillions of \\\n",
    "parameters, and are trained using self-supervised or semi-supervised learning \\\n",
    "methodologies. They have broad applicability across various industries, from \\\n",
    "marketing and sales to healthcare and finance, transforming processes, \\\n",
    "improving customer experiences, and enabling more efficient decision-making. \\\n",
    "Additionally, LLMs are poised to reshape the way we interact with technology \\\n",
    "and access information, making them a pivotal part of the modern digital \\\n",
    "landscape.\n",
    "    \"\"\"\n",
    "    summarize = dspy.ChainOfThought(\"document -> summary\")\n",
    "    response = summarize(document=document)\n",
    "    print(response.summary)\n",
    "    print(\"Rationale:\", response.rationale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Brasília', 'The capital of Brazil is Brasília.', 'Brasília', 'Brasília', 'Brasilia']\n",
      "Rationale: find the capital of Brazil. We know that Brazil is a big country in South America. We also know that each country has a capital city. So, the capital of Brazil must be a city in South America. We know that the country's capital is Brasília, so that must be the capital of Brazil.\n"
     ]
    }
   ],
   "source": [
    "with dspy.context(lm=turbo):\n",
    "    qa = dspy.ChainOfThought(\"question -> answer\", n=5)\n",
    "    response = qa(question=\"What is the capital of Brazil?\")\n",
    "    print(response.completions.answer)\n",
    "    print(\"Rationale:\", response.rationale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brasília\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Given the fields `question`, produce the fields `answer`.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: ${answer}\n",
      "\n",
      "---\n",
      "\n",
      "Question: What is the capital of Brazil?\n",
      "Answer:\u001b[32m Brasília\u001b[0m\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with dspy.context(lm=turbo):\n",
    "    model = ZeroShot()\n",
    "    question = \"What is the capital of Brazil?\"\n",
    "    response = model(question=question)\n",
    "    print(response.answer)\n",
    "    # Inspect\n",
    "    turbo.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joy\n"
     ]
    }
   ],
   "source": [
    "class Emotion(dspy.Signature):\n",
    "    \"\"\"Classify emotion among sadness, joy, love, anger, fear, surprise.\"\"\"\n",
    "\n",
    "    sentence = dspy.InputField()\n",
    "    sentiment = dspy.OutputField()\n",
    "\n",
    "\n",
    "sentence = \"Felling good today\"\n",
    "\n",
    "with dspy.context(lm=turbo):\n",
    "    classify = dspy.Predict(Emotion)\n",
    "    response = classify(sentence=sentence)\n",
    "    print(response.sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blue\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Answer the quesions with short factoid answers.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Reasoning: Let's think step by step in order to ${produce the answer}. We ...\n",
      "Answer: often between 1 and 5 words\n",
      "\n",
      "---\n",
      "\n",
      "Question: What is the color of the sky?\n",
      "Reasoning: Let's think step by step in order to\u001b[32m determine the color of the sky. We know that the sky is blue because of the way the atmosphere scatters sunlight.\n",
      "Answer: blue\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "Rationale: determine the color of the sky. We know that the sky is blue because of the way the atmosphere scatters sunlight.\n"
     ]
    }
   ],
   "source": [
    "class BasicQA(dspy.Signature):\n",
    "    \"\"\"Answer the quesions with short factoid answers.\"\"\"\n",
    "\n",
    "    question = dspy.InputField()\n",
    "    answer = dspy.OutputField(desc=\"often between 1 and 5 words\")\n",
    "\n",
    "\n",
    "with dspy.context(lm=turbo):\n",
    "    qa = dspy.ChainOfThought(BasicQA)\n",
    "    hint = \"It's what you often see during a sunny day.\"\n",
    "    response = qa(question=\"What is the color of the sky?\", hint=hint)\n",
    "    print(response.answer)\n",
    "    # Inspect\n",
    "    turbo.inspect_history(n=1)\n",
    "    print(\"Rationale:\", response.rationale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "class GenerateAnswer(dspy.Signature):\n",
    "    \"\"\"Answer questions with short factoid answers.\"\"\"\n",
    "\n",
    "    question = dspy.InputField()\n",
    "    answer = dspy.OutputField(desc=\"often between 1 and 5 words\")\n",
    "\n",
    "\n",
    "with dspy.context(lm=turbo):\n",
    "    pot = dspy.ProgramOfThought(GenerateAnswer)\n",
    "    question = \"Sarah has 5 apples. She buys 7 more apples from the store. How many apples does Sarah have now?\"\n",
    "    result = pot(question=question)\n",
    "    print(result.answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blue\n",
      "Rationale: determine the color of the sky. We know that the sky is blue because of the way the atmosphere scatters sunlight.\n"
     ]
    }
   ],
   "source": [
    "class BasicQA(dspy.Signature):\n",
    "    \"\"\"Answer questions with short factoid answers.\"\"\"\n",
    "\n",
    "    question = dspy.InputField()\n",
    "    answer = dspy.OutputField(desc=\"often between 1 and 5 words\")\n",
    "\n",
    "\n",
    "with dspy.context(lm=turbo):\n",
    "    react_module = dspy.ReAct(BasicQA)\n",
    "    question = \"What is the color of the sky?\"\n",
    "    result = react_module(question=question)\n",
    "    print(result.answer)\n",
    "    print(\"Rationale:\", response.rationale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The fox jumps over the lazy dog\n",
      "0.9\n"
     ]
    }
   ],
   "source": [
    "class Input(BaseModel):\n",
    "    context: str = Field(description=\"The context for the question\")\n",
    "    query: str = Field(description=\"The question to be answered\")\n",
    "\n",
    "\n",
    "class Output(BaseModel):\n",
    "    answer: str = Field(description=\"The answer for the question\")\n",
    "    confidence: float = Field(\n",
    "        ge=0, le=1, description=\"The confidence score for the answer\"\n",
    "    )\n",
    "\n",
    "\n",
    "class QASignature(dspy.Signature):\n",
    "    \"\"\"Answer the question based on the context and query provided, and on the scale of 10 tell how confident you are about the answer.\"\"\"\n",
    "\n",
    "    input: Input = dspy.InputField()\n",
    "    output: Output = dspy.OutputField()\n",
    "\n",
    "\n",
    "with dspy.context(lm=turbo):\n",
    "    predictor = dspy.TypedPredictor(QASignature)\n",
    "    doc_query_pair = Input(\n",
    "        context=\"The quick brown fox jumps over the lazy dog\",\n",
    "        query=\"What does the fox jumps over?\",\n",
    "    )\n",
    "    prediction = predictor(input=doc_query_pair)\n",
    "    answer = prediction.output.answer\n",
    "    confidence_score = prediction.output.confidence\n",
    "    print(answer)\n",
    "    print(confidence_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
